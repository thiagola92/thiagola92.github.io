---
authors: thiagola92
tags: [web, scraping, scrapers, crawlers, crawler, browser, html, http, css, xpath, puppeteer, playwright, selenium]
---

# Web Crawler
**Crawler**: Respons√°vel por navegar entre websites utilizando links encontrados neles mesmos  
**Scraper**: Respons√°vel por extrair informa√ß√µes importantes dos websites navegados  

Crawling √© ess√™ncial para scraping, pois voc√™ n√£o tem como conseguir extrair informa√ß√µes de um site sem navegar para ele antes.  
Scraping n√£o √© ess√™ncial para crawling, pois os dados do site podem ser irrelevantes para voc√™.  

Por exemplo:  
- Google utiliza um crawler para navegar a internet e indexar p√°ginas delas, por√©m n√£o extrai as informa√ß√µes dos websites em si
- OpenAI utiliza scraper para pegar os videos do youtube e utilizar na intelig√™ncia artificial deles

Se eu tivesse que separar crawlers em categorias, seria:
- **Browser**: Utilizando um browser real para crawlear
- **Raw**: Simulando um browser atr√°ves de requisi√ß√µes pela internet

Hoje em dia simular um navegador √© incrivelmente dif√≠cil ent√£o a maneira **raw** √© bem menos potente e fornece muito menos funcionalidades.  

## Browser
Existem 3 ferramentas famosas de automa√ß√£o de navegadores:  
- [Selenium](https://www.selenium.dev/)
- [Puppeteer](https://pptr.dev/)
- [Playwright](https://playwright.dev/)

√â importante notar que elas todas se declaram para usos de testes, por√©m ainda assim s√£o muito utilizadas para web scraping.  

### Selenium
Criado em ~2004 mas que continua a oferecer suporte para todos os navegadores e diversas linguagens (n√£o necessariamente bem).  

Muito do seu estilo vem do fato de ter sido criado utilizando Java e depois adaptado para outras linguagens.  

```javascript title="javascript"
import { Browser, Builder, By } from "selenium-webdriver";

const driver = await new Builder().forBrowser(Browser.CHROME).build()
await driver.get('https://www.etiquetaunica.com.br/')
await driver.manage().setTimeouts({implicit: 1000});

let hamburguerButton = await driver.findElement(By.xpath('//*[@id="headerWrapper"]/div[1]/button[1]'))
await hamburguerButton.click()

let brandButton = await driver.findElement(By.xpath('//*[@id="menu"]/div/div[2]/ul/li[7]/a'))
await brandButton.click()
```

### Puppeteer
Criado pela Google em ~2017 para fornecer automa√ß√£o ao Google Chrome utilizando JavaScript.  

Note que o locator favorito deles envolve utilizar CSS.  

```javascript title="javascript"
import puppeteer from "puppeteer";

const browser = await puppeteer.launch({headless: false})
const page = await browser.newPage()

await page.setViewport({ width: 1600, height: 1024 })
await page.goto('https://gringa.com.br/')
await page.locator('#section-header > div > div.Header__FlexItem.Header__FlexItem--fill.Header__FlexItem_left--mobile > nav > ul > li:nth-child(3) > a').click()
```

### Playwright
Criado pela Microsoft em ~2020 para fornecer automa√ß√£o em diversos navegador. O estilo √© bem parecido ao do Puppeteer pois boa parte dos desenvolvedores vieram do Puppeteer ü§£.  

A linguagem prim√°ria de programa√ß√£o dele √© JavaScript, por√©m fornece suporte a diversas outras (n√£o necessariamente bem).  

```javascript title="javascript"
import { chromium, devices } from "playwright";

const browser = await chromium.launch({ channel: 'chrome', headless: false })
const context = await browser.newContext(devices['Desktop Chrome'])
const page = await context.newPage()

await page.goto('https://canseivendi.com.br/')
await page.getByRole('link', {name: 'Marcas'}).click()
```

## Raw
Neste caso o mais importante √© voc√™ possuir uma boa quantidade de bibliotecas que o ajudem a realizar a tarefa! O b√°sico √© conseguir requisitar a p√°gina na internet e parsear o conte√∫do HTML.  

```python title="python"
import httpx
from parsel import Selector

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"

response = httpx.get(
    "https://canseivendi.com.br/bolsas",
    headers={"user-agent": USER_AGENT},
)

selector = Selector(text=response.text)
names = selector.xpath('//div[@class="name"]/a/text()').getall()
links = selector.xpath('//div[@class="name"]/a/@href').getall()
prices = selector.xpath('//div[@class="cash"]/text()').getall()
```

Neste exemplo escolhi utilizar a biblioteca [httpx](https://github.com/encode/httpx) (criada por [Encode](https://www.encode.io/)) e [parsel](https://github.com/scrapy/parsel) (criado por [Scrapy](https://scrapy.org/)), mas fica a sua escolha as bibliotecas para as tarefas.  

:::note
Navegadores fazem muito mais que apenas uma requisi√ß√£o! Uma p√°gina leva uma rea√ß√£o em cadeia de requisi√ß√µes por conte√∫dos delas.  

Por exemplo, ao receber uma p√°gina HTML e o navegador identificar uma imagem nela (`<img src="photo.jpg">`), ele precisa fazer uma requisi√ß√£o dessa imagem ao site.  

Agora imagina que isto acontece para diversos tipos de conte√∫dos da p√°gina:  
- Imagens: `<img src="myimage.jpg">`
- Audio: `<audio></audio>`
- Videos: `<video></video>`
- CSS: `<link rel="stylesheet" href="mystyle.css">`
- JavaScript: `<script src="myscripts.js"></script>`
- Iframe: `<iframe src="url"></iframe>`
:::

## Cat and Mouse Game
Ter os dados do seu site scrapeado por bots n√£o √© algo bom, pois eles geram grande tr√°fego e nenhum lucro (n√£o estou falando de [scalping](https://en.wikipedia.org/wiki/Ticket_resale#Automated_scalping_bots)).  

Por isto √© normal ver websites tentando identificar bots para bloquea-los e bots fingindo serem usu√°rios normais do dia a dia.  

Acontece que muitas vezes isso envolve simular comportamentos de um usu√°rio e simular um navegador, onde ambos n√£o s√£o tarefas f√°ceis.  

Aqui uma lista **pequena** de coisas a se pensar:
- Simular Navegador
    - Construir Headers
    - Analisar HTML
    - Executar JavaScript
    - Variar fingerprint
- Simular Usu√°rio
    - Resolver Captchas
    - Movimento do mouse
    - Velocidade digitando
- Ap√≥s ser bloqueado
    - Alterar comportamento/t√°tica
        - Para n√£o ser bloqueado novamente
    - Utilizar Proxy

Uma da melhor maneira de saber como atacar √© sabendo como os sites se protegem... O que √© algo que eu tenho pouco conhecimento ent√£o vou terminar aqui ü§£.  

## References
- https://substack.thewebscraping.club/p/browser-fingerprinting-test-online