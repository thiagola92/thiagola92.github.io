---
authors: thiagola92
tags: [web, scraping, scrapers, crawlers, crawler, browser, html, http, css, xpath, puppeteer, playwright, selenium]
---

# Web Crawler
**Crawler**: Respons√°vel por navegar entre websites utilizando links encontrados neles mesmos  
**Scraper**: Respons√°vel por extrair informa√ß√µes importantes dos websites navegados  

Crawling √© ess√™ncial para scraping, pois voc√™ n√£o tem como conseguir extrair informa√ß√µes de um site sem navegar para ele antes.  
Scraping n√£o √© ess√™ncial para crawling, pois os dados do site podem ser irrelevantes para voc√™.  

Por exemplo:  
- Google utiliza um crawler para navegar a internet e indexar p√°ginas delas, por√©m n√£o extrai as informa√ß√µes dos websites em si
- OpenAI utiliza scraper para pegar os videos do youtube e utilizar na intelig√™ncia artificial deles

Se eu tivesse que separar crawlers em categorias, seria:
- **Browser**: Utilizando um browser real para crawlear
- **Raw**: Simulando um browser atr√°ves de requisi√ß√µes pela internet

Hoje em dia simular um navegador √© incrivelmente dif√≠cil ent√£o a maneira **raw** √© bem menos potente e fornece muito menos funcionalidades.  

## Browser
Existem 3 ferramentas famosas de automa√ß√£o de navegadores:  
- [Selenium](https://www.selenium.dev/)
- [Puppeteer](https://pptr.dev/)
- [Playwright](https://playwright.dev/)

√â importante notar que elas todas se declaram para usos de testes, por√©m ainda assim s√£o muito utilizadas para web scraping.  

### Selenium
Criado em ~2004 mas que continua a oferecer suporte para todos os navegadores e diversas linguagens (n√£o necessariamente bem).  

Muito do seu estilo vem do fato de ter sido criado utilizando Java e depois adaptado para outras linguagens.  

```javascript title="javascript"
import { Browser, Builder, By } from "selenium-webdriver";

const driver = await new Builder().forBrowser(Browser.CHROME).build()
await driver.get('https://www.etiquetaunica.com.br/')
await driver.manage().setTimeouts({implicit: 1000});

let hamburguerButton = await driver.findElement(By.xpath('//*[@id="headerWrapper"]/div[1]/button[1]'))
await hamburguerButton.click()

let brandButton = await driver.findElement(By.xpath('//*[@id="menu"]/div/div[2]/ul/li[7]/a'))
await brandButton.click()
```

### Puppeteer
Criado pela Google em ~2017 para fornecer automa√ß√£o ao Google Chrome utilizando JavaScript.  

Note que o locator favorito deles envolve utilizar CSS.  

```javascript title="javascript"
import puppeteer from "puppeteer";

const browser = await puppeteer.launch({headless: false})
const page = await browser.newPage()

await page.setViewport({ width: 1600, height: 1024 })
await page.goto('https://gringa.com.br/')
await page.locator('#section-header > div > div.Header__FlexItem.Header__FlexItem--fill.Header__FlexItem_left--mobile > nav > ul > li:nth-child(3) > a').click()
```

### Playwright
Criado pela Microsoft em ~2020 para fornecer automa√ß√£o em diversos navegador. O estilo √© bem parecido ao do Puppeteer pois boa parte dos desenvolvedores vieram do Puppeteer ü§£.  

A linguagem prim√°ria de programa√ß√£o dele √© JavaScript, por√©m fornece suporte a diversas outras (n√£o necessariamente bem).  

```javascript title="javascript"
import { chromium, devices } from "playwright";

const browser = await chromium.launch({ channel: 'chrome', headless: false })
const context = await browser.newContext(devices['Desktop Chrome'])
const page = await context.newPage()

await page.goto('https://canseivendi.com.br/')
await page.getByRole('link', {name: 'Marcas'}).click()
```

## Raw
Neste caso o mais importante √© voc√™ possuir uma boa quantidade de bibliotecas que o ajudem a realizar a tarefa, por√©m o b√°sico √© conseguir requisitar a p√°gina na internet e parsear o conte√∫do HTML.  

```python title="python"
import httpx
from parsel import Selector

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"

response = httpx.get(
    "https://canseivendi.com.br/bolsas",
    headers={"user-agent": USER_AGENT},
)

selector = Selector(text=response.text)
names = selector.xpath('//div[@class="name"]/a/text()').getall()
links = selector.xpath('//div[@class="name"]/a/@href').getall()
prices = selector.xpath('//div[@class="cash"]/text()').getall()
```

Note que navegadores fazem muito mais que apenas uma requisi√ß√£o, pois uma p√°gina pode envolver fazer diversas requisi√ß√µes (por imagens, videos, c√≥digos javascripts, etc).  